{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df008e8e-53a4-485a-ba37-63a76d60a5a0",
   "metadata": {},
   "source": [
    "## Model Monitoring and Data Drift Analysis\n",
    "\n",
    "In this section, we perform data drift analysis using the alibi-detect library. We compare the training dataset with the production dataset—focusing on numeric features—to determine if significant drift exists. The output includes key metrics such as whether drift was detected, the p-value, and a distance measure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c33f423-5b02-4f81-a777-fc5ee8da770d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Metric                                                                                          Value\n",
      "0  Drift Detected                                                                                              0\n",
      "1         P-Value                     [0.3136755, 0.52932245, 0.80658126, 0.3400289, 0.9677855, 1.0, 0.99993527]\n",
      "2        Distance  [0.011649788, 0.009800986, 0.007752979, 0.011388713, 0.005971547, 0.0024533956, 0.0039208494]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from alibi_detect.cd import TabularDrift\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def detect_data_drift(train_file: str, prod_file: str, numeric_features: list, p_value_threshold: float = 0.05) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Detects data drift between training and production datasets using alibi_detect's TabularDrift.\n",
    "\n",
    "    Parameters:\n",
    "        train_file (str): File path to the training dataset (Parquet format).\n",
    "        prod_file (str): File path to the production dataset (Parquet format).\n",
    "        numeric_features (list): List of numeric feature column names to be analyzed.\n",
    "        p_value_threshold (float): The significance threshold for drift detection (default is 0.05).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame summarizing drift detection metrics including:\n",
    "                      - 'Drift Detected': Flag indicating if drift is detected (0 or 1)\n",
    "                      - 'P-Value': Statistical significance of the drift test for each feature\n",
    "                      - 'Distance': A measure of the distance between distributions for each feature\n",
    "    \"\"\"\n",
    "    # Load the training and production datasets from Parquet files.\n",
    "    train_df = pd.read_parquet(train_file)\n",
    "    prod_df = pd.read_parquet(prod_file)\n",
    "    \n",
    "    # Drop the target column 'y' to focus only on the features.\n",
    "    X_train = train_df.drop(columns=['y'])\n",
    "    X_prod = prod_df.drop(columns=['y'])\n",
    "    \n",
    "    # Extract the numeric features from the datasets as numpy arrays.\n",
    "    X_train_numeric = X_train[numeric_features].values\n",
    "    X_prod_numeric = X_prod[numeric_features].values\n",
    "    \n",
    "    # Initialize the TabularDrift detector with the training data as the reference distribution.\n",
    "    cd = TabularDrift(X_train_numeric, p_val=p_value_threshold)\n",
    "    \n",
    "    # Run the drift detector on the production data.\n",
    "    preds = cd.predict(X_prod_numeric)\n",
    "    \n",
    "    # Extract drift detection results.\n",
    "    drift_detected = preds['data']['is_drift']\n",
    "    p_value = preds['data']['p_val']\n",
    "    distance = preds['data']['distance']\n",
    "    \n",
    "    # Organize the metrics into a DataFrame for tabular display.\n",
    "    results = pd.DataFrame({\n",
    "        'Metric': ['Drift Detected', 'P-Value', 'Distance'],\n",
    "        'Value': [drift_detected, p_value, distance]\n",
    "    })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Define the list of numeric features as per the dataset schema.\n",
    "numeric_features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Disable column width truncation so that full lists are displayed.\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Call the function to perform drift detection on the training and production datasets.\n",
    "results = detect_data_drift(\n",
    "    train_file='Datasets/Processed/banking_data_train.parquet',\n",
    "    prod_file='Datasets/Processed/banking_data_prod.parquet',\n",
    "    numeric_features=numeric_features\n",
    ")\n",
    "\n",
    "# Print the drift detection results with full details.\n",
    "print(results.to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ee019-8b69-46b0-91c4-c558f6d39739",
   "metadata": {},
   "source": [
    "***The numeric features in the production dataset are consistent with those in the training dataset. The high p-values and low distance metrics indicate that there is no statistically significant drift in these features. This stability implies that the model's performance is unlikely to be impacted by changes in the numeric data distribution over time.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e186cd2-1aa4-418d-8315-31167ebca0ab",
   "metadata": {},
   "source": [
    "## Categorical Data Drift Analysis\n",
    "\n",
    "In this section, we perform drift detection for categorical features. For each categorical column, we compare the frequency distributions in the training and production datasets using a chi-square test. The output includes the chi-square statistic, p-value, and a flag indicating whether drift is detected (using a significance threshold of 0.05).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65a6f1e0-c096-460b-9e28-7cbf128bf270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Feature  Chi2 Statistic   p-value  Drift Detected\n",
      "0        job        7.223676  0.780691               0\n",
      "1    marital        3.574436  0.167425               0\n",
      "2  education       10.889839  0.012337               1\n",
      "3    default        1.053602  0.304679               0\n",
      "4    housing        0.146600  0.701806               0\n",
      "5       loan        0.320922  0.571054               0\n",
      "6    contact        2.442812  0.294815               0\n",
      "7      month       10.720298  0.466985               0\n",
      "8   poutcome        5.239725  0.155062               0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def detect_categorical_drift(train_file: str, prod_file: str, categorical_features: list, alpha: float = 0.05) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Detects drift in categorical features using the chi-square test.\n",
    "    \n",
    "    For each categorical feature, this function computes the frequency distributions in both the training \n",
    "    and production datasets, aligns them by their categories, and then applies the chi-square test to determine \n",
    "    if the distributions differ significantly.\n",
    "    \n",
    "    Parameters:\n",
    "        train_file (str): File path to the training dataset (Parquet format).\n",
    "        prod_file (str): File path to the production dataset (Parquet format).\n",
    "        categorical_features (list): List of categorical feature column names to be analyzed.\n",
    "        alpha (float): Significance level for the chi-square test (default is 0.05).\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame summarizing the drift detection results for each feature, including:\n",
    "                      - Feature: Name of the categorical feature.\n",
    "                      - Chi2 Statistic: The chi-square test statistic.\n",
    "                      - p-value: The p-value from the chi-square test.\n",
    "                      - Drift Detected: 1 if drift is detected (p < alpha), otherwise 0.\n",
    "    \"\"\"\n",
    "    # Load training and production datasets from Parquet files.\n",
    "    train_df = pd.read_parquet(train_file)\n",
    "    prod_df = pd.read_parquet(prod_file)\n",
    "    \n",
    "    # Drop the target column 'y' from both datasets.\n",
    "    X_train = train_df.drop(columns=['y'])\n",
    "    X_prod = prod_df.drop(columns=['y'])\n",
    "    \n",
    "    # List to store results for each categorical feature.\n",
    "    results = []\n",
    "    \n",
    "    # Iterate over each categorical feature to perform drift detection.\n",
    "    for col in categorical_features:\n",
    "        # Get frequency counts for each category in training and production datasets.\n",
    "        train_counts = X_train[col].value_counts().sort_index()\n",
    "        prod_counts = X_prod[col].value_counts().sort_index()\n",
    "        \n",
    "        # Determine the union of categories present in either dataset.\n",
    "        all_categories = sorted(set(train_counts.index) | set(prod_counts.index))\n",
    "        \n",
    "        # Reindex counts to include all categories; fill missing values with 0.\n",
    "        train_counts = train_counts.reindex(all_categories, fill_value=0)\n",
    "        prod_counts = prod_counts.reindex(all_categories, fill_value=0)\n",
    "        \n",
    "        # Create a contingency table where rows represent datasets and columns represent categories.\n",
    "        contingency_table = pd.DataFrame({\n",
    "            'train': train_counts,\n",
    "            'prod': prod_counts\n",
    "        })\n",
    "        \n",
    "        # Perform the chi-square test on the transposed contingency table.\n",
    "        # Transposing so that each row represents one dataset.\n",
    "        chi2, p, dof, expected = chi2_contingency(contingency_table.T)\n",
    "        \n",
    "        # Determine if drift is detected based on the p-value.\n",
    "        drift_flag = 1 if p < alpha else 0\n",
    "        \n",
    "        # Append the results for this feature.\n",
    "        results.append({\n",
    "            'Feature': col,\n",
    "            'Chi2 Statistic': chi2,\n",
    "            'p-value': p,\n",
    "            'Drift Detected': drift_flag\n",
    "        })\n",
    "    \n",
    "    # Convert the list of results into a DataFrame and return it.\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Define the list of categorical features as per the dataset schema.\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "\n",
    "# Call the function to perform drift detection on the training and production datasets.\n",
    "categorical_results = detect_categorical_drift(\n",
    "    train_file='Datasets/Processed/banking_data_train.parquet',\n",
    "    prod_file='Datasets/Processed/banking_data_prod.parquet',\n",
    "    categorical_features=categorical_features\n",
    ")\n",
    "\n",
    "# Ensure full output is displayed without truncation.\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(categorical_results.to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6425381b-d901-47bc-8e8a-5471e3de259e",
   "metadata": {},
   "source": [
    "***Although the chi-square test detected drift in the 'education' feature (with a p-value below 0.05), this is most likely due to normal sampling variability from the random split of the same dataset. The majority of categorical features show no significant drift, indicating that the training and production splits are largely consistent. The apparent drift in 'education' is a statistical artifact rather than a true change in the underlying data distribution.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75704208-9af1-46ec-b35e-0f2a766a9379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
